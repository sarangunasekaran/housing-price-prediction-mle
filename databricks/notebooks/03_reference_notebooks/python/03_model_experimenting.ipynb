{"cells":[{"cell_type":"markdown","source":["# Purpose"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ab4aec8-93cc-40e5-b60f-cc7ba070f2ee"}}},{"cell_type":"markdown","source":["This notebook demonstrates the model experimentation and finalization. It covers EDA, outlier treatment, transformation, training, model evaluation and comparison across models."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9203f7e-33a4-425d-b165-1372f913c7da"}}},{"cell_type":"markdown","source":["## Imports"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db66e159-5901-488c-91bc-1a9888e2947a"}}},{"cell_type":"code","source":["from ta_lib.core.api import get_package_path\nPACKAGE_PATH=get_package_path()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"36b65ef5-111f-4490-ac92-a999f7dd4551"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["import sys\nimport os.path as op\nCURR_LOC_IN_DBFS=op.join(PACKAGE_PATH,\"..\",\"databricks/03_reference_notebooks/python/\")\nsys.path.append(CURR_LOC_IN_DBFS)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64e63869-ea34-4654-a9ca-afeb27e01220"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["import os\nimport os.path as op\nimport shutil\n\n# standard third party imports\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.compose import ColumnTransformer\n\n# impute missing values\nfrom sklearn.experimental import enable_iterative_imputer  # noqa\nfrom sklearn.impute import KNNImputer, IterativeImputer, SimpleImputer\nfrom sklearn.tree import DecisionTreeRegressor\nfrom category_encoders import TargetEncoder\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06eee446-f12d-4b87-ba56-38e7868b8bb7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%load_ext autoreload\n%autoreload 2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9014d13b-c50d-4d41-acfa-ce98f21c5ba8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# standard code-template imports\nfrom ta_lib.core.api import (\n    create_context, get_dataframe, get_feature_names_from_column_transformer, string_cleaning,\n    display_as_tabs, save_pipeline, load_pipeline, initialize_environment,\n    load_dataset, save_dataset, DEFAULT_ARTIFACTS_PATH\n)\n\nimport ta_lib.eda.api as eda\nfrom xgboost import XGBRegressor\nfrom ta_lib.regression.api import SKLStatsmodelOLS\nfrom ta_lib.regression.api import RegressionComparison, RegressionReport\nimport ta_lib.reports.api as reports\nfrom ta_lib.data_processing.api import Outlier\n\ninitialize_environment(debug=False, hide_warnings=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18aea6b0-93e6-4ce3-bfc1-ad8472841323"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Initialization"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"849c0883-c23e-4eb6-8f83-ca8f4d2d35a4"}}},{"cell_type":"code","source":["artifacts_folder = DEFAULT_ARTIFACTS_PATH\nREPORT_LOC = op.join(PACKAGE_PATH,'..','databricks')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"578382e3-4c0a-4cd1-a56f-44af9342c5fe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["config_path = op.join(CURR_LOC_IN_DBFS,\"conf\",\"config.yml\")\ncontext = create_context(config_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a9a7e1b-e6f5-4f60-b4fc-bb85d14beebf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# 3 Feature Engineering\n\nThe focus here is the `Pipeline` and not the model. Though the model would inform the pipeline that is needed to train the model, our focus is to set it up in such a way that it can be saved/loaded, tweaked for different model choices and so on."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"75734a55-8418-4904-8d42-d0b7115a7fce"}}},{"cell_type":"markdown","source":["## 3.1 Read the Train and Test Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f2e65e4-8b8f-468e-b415-33c7854a3cad"}}},{"cell_type":"code","source":["train_X = load_dataset(context, 'train/sales/features')\ntrain_y = load_dataset(context, 'train/sales/target')\nprint(train_X.shape, train_y.shape)\n\ntest_X = load_dataset(context, 'test/sales/features')\ntest_y = load_dataset(context, 'test/sales/target')\nprint(test_X.shape, test_y.shape)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e6e8aaf-6660-4c5b-b927-8f6286215e1c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 3.2 Feature Engineering Pipelines"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7a7f577-ba1a-49d9-b7b0-4a6ad97fecf7"}}},{"cell_type":"markdown","source":["**Dev NOTES**\n\nFor Feature Engineering and Model Building sklearn.pipeline.Pipeline are leveraged because of the following advantages\n<details>\n    \n1. It helps in automating workflows and are easier to read and comprehend.\n2. Right Sequence can be ensured and (for example always encodes before imputing)\n3. Reproducibility is very convenient with pipelines\n4. Pipelines help you prevent data leakage in your test data\n5. Code is near implementation ready"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7382430e-0b94-4fc1-ae0a-0edbc691ea65"}}},{"cell_type":"markdown","source":["#### General Steps in the Feature Transformation are as follows\n - Outlier Treatment\n - Encoding of Categorical Columns\n - Missing Values Imputation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14db58f4-e1f0-4749-a5e8-e6dd3d75c277"}}},{"cell_type":"code","source":["# collecting different types of columns for transformations\ncat_columns = train_X.select_dtypes('object').columns\nnum_columns = train_X.select_dtypes('number').columns"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5a2a261-7702-4bc7-b661-92aa51dd6b5b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Outlier Handling\n- A Custom Transformer is used to handle outliers. It is not included as part of the pipeline as outliers handling are optional for test data\n- An option to either drop or cap the outliers can be passed during the transform call\n- If we want to treat outliers for some columns them we can pass cols argument to the Transformer\n- This will go into production code"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6f685b1-8842-4223-8c93-8bfa95a124ee"}}},{"cell_type":"code","source":["outlier_transformer = Outlier(method='mean')\nprint(train_X.shape)\ntrain_X = outlier_transformer.fit_transform(train_X)\nprint(train_X.shape)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"16d2d904-0353-4f79-885c-510748c2b3e0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Encoding"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e675f55-9781-42fd-a5cc-440f1376733c"}}},{"cell_type":"markdown","source":["Some sample pipelines showcasing how to create column specific pipelines and integrating them overall is presented below\n\n- Commonly target encoding is done for categorical variables with too many levels.\n- We also group sparse levels. For fewer levels one hot encoding/label encoding is preferred.\n- If there is one dominant level, we can use binary encoding.\n- This will go into production code"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8913b6ea-7e4f-4376-8acb-a2a5c822b235"}}},{"cell_type":"code","source":["tgt_enc_simple_impt = Pipeline([\n    ('target_encoding', TargetEncoder(return_df=False)),\n    ('simple_impute', SimpleImputer(strategy='most_frequent')),\n])\n\n\n# NOTE: the list of transformations here are not sequential but weighted \n# (if multiple transforms are specified for a particular column)\n# for sequential transforms use a pipeline as shown above.\nfeatures_transformer = ColumnTransformer([\n    \n    ## categorical columns\n    ('tgt_enc', TargetEncoder(return_df=False),\n     list(set(cat_columns) - set(['technology', 'functional_status', 'platforms']))),\n    \n    # NOTE: if the same column gets repeated, then they are weighed in the final output\n    # If we want a sequence of operations, then we use a pipeline but that doesen't YET support\n    # get_feature_names. \n    ('tgt_enc_sim_impt', tgt_enc_simple_impt, ['technology', 'functional_status', 'platforms']),\n        \n    ## numeric columns\n    ('med_enc', SimpleImputer(strategy='median'), num_columns),\n    \n])\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b48619c-d3d7-43dd-9343-ba8a7831065a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Dev notes(Encoding):**\n<details>\n\n    Some common practices followed in Categorical Feature Encoding are\n    * For categorical variables with too many levels, target encoding can be done.\n    * For fewer levels, one hot encoding can be done.\n    * If one very dominant level is observed, binary encoding can be used.\n    \n    \n</details>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2f7a80b4-fda5-441f-9cfb-5432e761027d"}}},{"cell_type":"markdown","source":["## 3.2 Feature analysis\n\nUsing the pipeline above analyze the features and decide on additional features to add/remove from the pipeline. This section will not be part of the production code, unless input data drifts etc. are explicitly demanded in the project.\n\nHere we are primarily focused on feature selection/elimination based on business rules, prior knowledge, data analysis.\n\n**We are not building any models at this point.**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"284e567f-09e6-400f-8170-1d408f73a9c9"}}},{"cell_type":"markdown","source":["- we create some sample data to analyze that we assume represent the population\n- train the features transformer and do the analysis as below"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca072aee-c3cf-4fab-a36f-149daa96dfdd"}}},{"cell_type":"code","source":["sample_X = train_X.sample(frac=0.1, random_state=context.random_seed)\nsample_y = train_y.loc[sample_X.index]\n\nsample_train_X = get_dataframe(\n    features_transformer.fit_transform(sample_X, sample_y), \n    get_feature_names_from_column_transformer(features_transformer)\n)\n\n# nothing to do for target\nsample_train_y = sample_y"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0271949-cd88-4a0e-888c-099339ceaa40"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Running the features transformer on the complete data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d848157f-539a-4b9a-8cd7-26a6b563247c"}}},{"cell_type":"code","source":["train_X = get_dataframe(\n    features_transformer.fit_transform(train_X, train_y), \n    get_feature_names_from_column_transformer(features_transformer)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5ef17a8-1ad9-4702-8ccd-ac785c56c62b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 3.2.1 Univariate\n\n\n- Look at each variable independently. This is useful if your models have assumptions on the distribution and/or bounds on the features/target"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff060ee9-1821-4bab-9e1a-fac608150363"}}},{"cell_type":"code","source":["out = eda.get_density_plots(train_X, cols=['brand', 'condition'])\nout"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d58de68-c694-4f69-9c74-3b792d2d9b37"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# save the plots are html\nreports.create_report({'univariate': out}, name='feature_analysis_univariate')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"075c0355-31e6-4c9b-90f0-e990ec93667c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["A report containing the above plot is available [here](https://drive.google.com/file/d/1oqlhJ_GifdEXOT0mOqnGoOIwBt1e5jd2/view?usp=sharing)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b07dbbb-9d90-45a1-a412-b4391b4c0691"}}},{"cell_type":"markdown","source":["Alternatively, the above plots can be generated as a single html as below. The output from this is available [here](https://drive.google.com/file/d/1mWvPLC2eAEIfNqIYDKpWuAwP6kInkMbw/view?usp=sharing)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f95ec2dc-426e-40a7-8c2e-3b18f86153b6"}}},{"cell_type":"code","source":["reports.feature_analysis(train_X,REPORT_LOC+'/feature_analysis_report.html')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b3c8e62f-9959-4096-8120-5123df459307"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 3.2.2 Bivariate - mutual interactions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2157d2a6-3413-4b71-b9af-cc7c716ce014"}}},{"cell_type":"markdown","source":["- Find columns with high correlations and drop them"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b18631d-d402-4513-ac0c-b6886ccaf504"}}},{"cell_type":"code","source":["out = eda.get_correlation_table(train_X)\nout[out[\"Abs Corr Coef\"] > 0.6]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe6ecf69-9726-4d12-9a19-0ae67b2f5a34"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# channel and source_channel highly correlated. So discarding source_channel\n# brand and manufacturer are almost same so discarding manufacturer.\n# Similarly keeping sku between inventory and sku\n# Similarly keeping condition between conditions and ext_grade\n# Similarly keeping model_family between platforms, ext_model_family and model_family\n# Discarding selling price & selling cost as they are multiples of unit price/cost & quantity.\n# Discarding gp as it is the of selling price and selling cost\n# order_no, line, invoice_no & customername cannot be IDVs\ncurated_columns = list(\n    set(train_X.columns.to_list()) \n    - set(['manufacturer', 'inventory_id', 'ext_grade', 'source_channel',\n           'tgt_enc_iter_impt_platforms', 'ext_model_family',\n           'order_no', 'line', 'inventory_id',\n           'gp', 'selling_price', 'selling_cost','invoice_no','customername'])\n)\n\ntrain_X = train_X[curated_columns]\n\nout = eda.get_correlation_table(train_X)\nout[out[\"Abs Corr Coef\"] > 0.6]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c91df2f-9cf3-4d48-b763-8e9a877232d0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["out = eda.get_bivariate_plots(train_X, x_cols=['brand'], y_cols=['color'])\nout"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bde1caa1-ce40-448a-98ee-fc526568c48e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%%time\n# create reports as needed\ncols = train_X.columns.to_list()\nall_plots = {}\nfor ii, col1 in enumerate(cols): \n    for jj in range(ii+1, len(cols)):\n        col2 = cols[jj]\n        out = eda.get_bivariate_plots(train_X, x_cols=[col1], y_cols=[col2])\n        all_plots.update({f'{col2} vs {col1}': out})\n\nreports.create_report(all_plots, path=REPORT_LOC,name='feature_analysis_bivariate')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68f79d1a-9e7e-4b9f-9776-f75c99323d1f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["A report containing the bivariate plot is available [here](https://drive.google.com/file/d/1S3JXE1TTwuALugqL5I4zsRpjYy9vIXZy/view?usp=sharing)\n\nAlternatively, the above plots can be generated as a single html as below. The output from this is available [here](https://drive.google.com/file/d/12o2Q7O6q2Zck0cHBQ36WDeWuy7b4athM/view?usp=sharing)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9da0dcd7-a531-4052-9a13-42f89d4322c0"}}},{"cell_type":"code","source":["reports.feature_interactions(train_X,REPORT_LOC+'/feature_interaction_report.html')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a16c9ec-ec56-4df6-b564-b18ac78d5bc7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 3.2.3 Key Drivers - Interaction with Target variable"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"034cefc9-fad7-4633-a1c0-d0d647d37322"}}},{"cell_type":"code","source":["out = eda.get_target_correlation(train_X, train_y)\ndisplayHTML(display_as_tabs([(k, v) for k,v in out.items()], cloud_env=\"Databricks\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a24b2c91-eed8-4b63-aaa9-75b94f29c105"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["out = eda.get_feature_importances(train_X, train_y)\ndisplayHTML(display_as_tabs([(k, v) for k,v in out.items()], cloud_env=\"Databricks\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2497ff71-4d2d-40ae-9f2f-f4be56092241"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Key drivers report like feature importance, bivariate plots can be obtained as below"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c48098a8-e464-4f6d-b2d4-383d4d7764fa"}}},{"cell_type":"code","source":["reports.key_drivers(train_X,train_y,REPORT_LOC+'/key_drivers_report.html')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72481784-4bb5-4948-98bc-4ec541c3e227"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Dev Notes**\n<details>\n    \n- The SHAP plots and bivariate plots in key drivers reports can be obtained by including quick=False as a parameter to key_drivers function call. \n- SHAP plots and bivariate plots often take long depending on data shape.\n- The plot with shap is present [here](https://drive.google.com/file/d/1JOTMBLiv3LEqZ-kxZz0RokW9v5UyiGva/view?usp=sharing)\n\n</details>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f8852d5-b813-4325-a500-eec932399416"}}},{"cell_type":"markdown","source":["All the plots like feature analysis, interaction, key drivers can be obtained as a single plot using data exploration method as shown below. The output from this is available [here](https://drive.google.com/file/d/1_3rE5u3qFHdeoL3VrFNTG-aBtHFALnI7/view?usp=sharing)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"716095a9-6299-4e25-be07-7d4f43612011"}}},{"cell_type":"code","source":["reports.data_exploration(train_X,train_y,REPORT_LOC+'/data_exploration_report.html')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc8aa8de-6996-4c99-8d73-344d45da9f72"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# saving the list of relevant columns\nsave_pipeline(curated_columns, op.abspath(op.join(artifacts_folder, 'curated_columns.joblib')))\n\n# save the feature pipeline\nsave_pipeline(features_transformer, op.abspath(op.join(artifacts_folder, 'features.joblib')))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04ed28e8-374b-4d7d-86e4-b8f27db248a9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# 4 Modelling"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3bc7dbee-8bcf-412f-bf98-dea4491ce9b3"}}},{"cell_type":"markdown","source":["## 4.1 Modelling - Linear Regression"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6d74e0e-fbae-4245-bece-5e4cda5f3ed4"}}},{"cell_type":"markdown","source":["### 4.1.1 Feature Selection(Specific to Regression)\n\n- Selecting Features specific to regression\n- VIF : measure of the amount of multi-collinearity in a set of multiple regressor variables. \n- On a case to case basis VIF thresholds change. Generally 5 or 10 are acceptable levels.\n- Usually on a recursive basis when removing the most collinear variable, there can be shuffle in VIF. \n- Often this section will not be part of the production code."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4ede3736-7279-4151-8e6f-1aaad423a9ee"}}},{"cell_type":"code","source":["cols = list(train_X.columns)\nvif = eda.calc_vif(train_X)\nwhile max(vif.VIF) > 15:\n    #removing the largest variable from VIF\n    cols.remove(vif[(vif.VIF==vif.VIF.max())].variables.tolist()[0])\n    vif = eda.calc_vif(train_X[cols])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a93cc5ec-4f35-44bf-9986-6904585f3ba8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["reg_vars = vif.query('VIF < 15').variables\nreg_vars = list(reg_vars)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f75fbb9c-5573-41b5-9097-557615e7229e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 4.1.2 Data transformations"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e9e7772-f38f-480e-b2a6-cce0db6221cf"}}},{"cell_type":"code","source":["# Custom Transformations like these can be utilised\ndef _custom_data_transform(df, cols2keep=None):\n    \"\"\"Transformation to drop some columns in the data\n    \n    Parameters\n    ----------\n        df - pd.DataFrame\n        cols2keep - columns to keep in the dataframe\n    \"\"\"\n    cols2keep = cols2keep or []\n    if len(cols2keep):\n        return (df\n                .select_columns(cols2keep))\n    else:\n        return df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d2c49ee-4f2a-442a-9a16-aed4102d14db"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 4.1.3 Model training pipeline\n\n- Here we focus on creating a collection of pipelines that can be used for training respective models.\n- Each model pipeline will essentially be of the form\n```\n[\n('preprocessing', preprocessing_pipeline),\n('feature_selection', feature_selection_pipeline),\n('estimator', estimator),\n]\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"93d3e440-475f-4957-9270-fe6e42a0f385"}}},{"cell_type":"markdown","source":["### 4.1.4 Model Pipeline Build\n\n- This will be part of the production code (training only)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d1663736-a8fa-4715-82b8-306a7cd866fa"}}},{"cell_type":"code","source":["reg_ppln_ols = Pipeline([\n    ('',FunctionTransformer(_custom_data_transform, kw_args={'cols2keep':reg_vars})),\n    ('estimator', SKLStatsmodelOLS())\n])\nreg_ppln_ols.fit(train_X, train_y.values.ravel())\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4eb05726-4c5b-4b67-9c4d-acbd0665927c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["reg_ppln_ols['estimator'].summary()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9112d71f-b08e-4b76-af24-de0079626388"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 4.1.5 Model Evaluation(Linear Model)\n\nThis will be part of the production code."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df93ac87-87dd-4064-a86b-d29420ebc208"}}},{"cell_type":"code","source":["reg_ppln = Pipeline([\n    ('', FunctionTransformer(_custom_data_transform, kw_args={'cols2keep':reg_vars})),\n    ('Linear Regression', SKLStatsmodelOLS())\n])\n\ntest_X = get_dataframe(\n    features_transformer.transform(test_X), \n    get_feature_names_from_column_transformer(features_transformer)\n)\ntest_X = test_X[curated_columns]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51086c26-d914-490f-bac0-6d4148b35d3e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["reg_linear_report = RegressionReport(model=reg_ppln, x_train=train_X, y_train=train_y, x_test= test_X, y_test= test_y, refit=True)\nreg_linear_report.get_report(include_shap=False, file_path=REPORT_LOC+'/regression_linear_model_report')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c5f952f-7b7b-4a31-ab28-000202c7856b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Dev Notes**\nUse SHAP for variable interpretability.\n<details>\n\n    1. Use SHAP=True to generate variable interpretability plots in the report\n    2. SHAP is recommended for non parameteric models such as RF, xgboost.\n    3. However, SHAP reports are time consuming depending on no.of records and model complexity.\n    \nA sample of regerssion report with SHAP can be found [here](https://drive.google.com/file/d/18RlQTsT1ze09Cgz-qpb4ha_cvyWbN5F5/view?usp=sharing).\n</details>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"124d1c65-c47a-4c02-b52d-d87eaa990f41"}}},{"cell_type":"markdown","source":["### 4.1.6 Residual Analysis\n- After scoring the model, it is recommended to do a residual analysis to know the distribution of errors\n- we took a threshold of 30% above which it is marked as over prediction or underprediction\n- This will not be part of the production code."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87c12964-7cc6-43ff-b39f-957baa8edd6f"}}},{"cell_type":"code","source":["threshold=0.3\nresidual_analysis = test_X.copy()\nresidual_analysis['prediction'] = reg_ppln_ols.predict(test_X)\nresidual_analysis['actuals'] = test_y.reset_index(drop = True).iloc[:,0].values\nresidual_analysis['forecast_flag'] = 'good'\nresidual_analysis.loc[((residual_analysis['prediction'] > (1+threshold) * residual_analysis['actuals'])\\\n                       & (residual_analysis['actuals']>100)),'forecast_flag'] = 'over predict'\nresidual_analysis.loc[((residual_analysis['prediction'] < (1-threshold) * residual_analysis['actuals'])\\\n                       & (residual_analysis['actuals']>100)),'forecast_flag'] = 'under predict'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2d5cd52-315e-48ad-80ad-8c05480a48cb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["residual_analysis.hvplot.kde(y=\"unit_cost\",by=\"forecast_flag\", ## Grouping by Predictions\n                                width=800, height=400,\n                                alpha=0.7,\n                                ylabel=\"density\",\n                                xlabel=\"unit_cost\",\n                                title=f'unit cost(density)',legend='top_right')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e4866844-949e-4606-827c-191f53b0c5ff"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["- From the above plot we can infer that the higher \"over predictions\" are happening for unit_cost > 200.\n- similarly, the higher \"under predictions\" are happening for unit_cost is zero.\n\nThis can help us tune the model by a separate model for unit_cost > 200"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5809d62-808b-4cf9-a395-c300726da41d"}}},{"cell_type":"markdown","source":["# 4.2 Modelling - XGBoost"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e4ffc03-ac74-4cd0-8f83-d45cc2e67c25"}}},{"cell_type":"markdown","source":["## 4.2.1 Model training pipeline\n\nHere we focus on creating a collection of pipelines that can be used for tranining respective models.\n\nEach model pipeline will essentially be of the form\n```\n[\n('preprocessing', preprocessing_pipeline),\n('feature_selection', feature_selection_pipeline),\n('estimator', estimator),\n]\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3db05e1-824b-4547-845a-b8aea260d9b1"}}},{"cell_type":"markdown","source":["### 4.2.2 Model Pipeline Build"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07a71971-73f3-4d5d-93c0-ad9af265a197"}}},{"cell_type":"code","source":["# let's find features for some decent defaults\nestimator = XGBRegressor()\nxgb_training_pipe_init = Pipeline([\n    ('XGBoost', XGBRegressor())\n])\nxgb_training_pipe_init.fit(train_X, train_y)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e785e37b-b538-4b51-800e-70f84f213ee5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 4.2.3 Model Tuning"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6712e02c-8d22-46b4-9862-a9c71f22477a"}}},{"cell_type":"code","source":["# Understanding the Feature Importance\n%matplotlib inline\nimp = pd.DataFrame({'importance': xgb_training_pipe_init['XGBoost'].feature_importances_})\nimp.index = train_X.columns\nimp.sort_values('importance',inplace=True)\nimp.plot(kind='barh')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b746a15d-a03b-4e89-a136-b0fe64a5dea3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["'condition','model_family','days_since_last_purchase','first_time_customer','sales_person', are considered to be important and in grid search"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee2aecdb-bfe4-4cb2-9deb-61a286f4d5d5"}}},{"cell_type":"markdown","source":["##### Pipeline build based on new importance features"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d97d2045-89d5-4392-b840-5e221898711b"}}},{"cell_type":"code","source":["# let's find features for some decent defaults\nimp_features = ['model_family','sku','unit_cost','condition','brand','business_unit']\n\nestimator = XGBRegressor()\nxgb_training_pipe2 = Pipeline([\n    ('', FunctionTransformer(_custom_data_transform, kw_args={'cols2keep':imp_features})),\n    ('XGBoost', XGBRegressor())\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed946712-b9f1-4c03-8f43-400bd1e34098"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Grid Search of the Estimator"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b42a8338-1e7c-4e27-9d93-5451bb02b7e4"}}},{"cell_type":"code","source":["%%time\nparameters = {\n   'gamma':[0.03],\n   'min_child_weight':[6],\n   'learning_rate':[0.1],\n   'max_depth':[3],\n   'n_estimators':[500], \n}\nest = XGBRegressor()\nxgb_grid = GridSearchCV(est,\n                        parameters,\n                        cv = 2,\n                        n_jobs = 4,\n                        verbose=True)\n\nxgb_grid.fit(train_X, train_y)\n\nprint(xgb_grid.best_score_)\nprint(xgb_grid.best_params_)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f2ec86b-2228-4202-b396-5fe45d2c1454"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Pipeline Build using the best estimator"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc8b3b88-3e68-4806-b6b3-739a5ec8c13d"}}},{"cell_type":"code","source":["xgb_pipeline_final = Pipeline([\n    ('', FunctionTransformer(_custom_data_transform, kw_args={'cols2keep':imp_features})),\n    ('XGBoost', xgb_grid.best_estimator_)\n])\nxgb_pipeline_final.fit(train_X, train_y)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ecf4fe1e-498f-43e9-89c5-39944ae3eef7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["reg_tree_report = RegressionReport(model=xgb_pipeline_final, x_train=train_X, y_train=train_y, x_test= test_X, y_test= test_y)\nreg_tree_report.get_report(include_shap=False, file_path=REPORT_LOC+'/regression_tree_model_report')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0b93e73-afcb-47d6-960d-8de380d4b0f8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The Regression report containing the feature importances are available [here](https://drive.google.com/file/d/1-VvhnH-TELL_SYQP1SA91KeGbSI48bCl/view?usp=sharing)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc2f0eef-9bcb-4bd6-9596-8ddd204f08e6"}}},{"cell_type":"markdown","source":["# 5 Model Comparison"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee6105b0-be1e-4fb0-95ed-c0680cd73132"}}},{"cell_type":"markdown","source":["Now, a comparison report of the  linear (vs) tree -based model  approach can be generated as follows.\n\nThis code will not be part of the production code."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb65350c-113a-46ac-a990-e69fc4e58069"}}},{"cell_type":"code","source":["model_pipelines = [reg_ppln, xgb_pipeline_final]\nmodel_comparison_report = RegressionComparison(models=model_pipelines,x=train_X, y=train_y)\nmetrics = model_comparison_report.get_report(file_path=REPORT_LOC+'/regression_comparison')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8904466f-38a5-49a1-90f4-0a4ddb183342"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["model_comparison_report.performance_metrics"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5c6f1f7-1e8c-4d66-b770-1566e3b9d94a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["A report comparing the performance, metrics between Linear model and Tree model are available [here](https://drive.google.com/file/d/1t2VtBffSH5gfhxyaXZrfNufuRgMFZhc9/view?usp=sharing)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a39c3c6b-20e4-434b-a74b-1ac5455346ad"}}},{"cell_type":"markdown","source":["**Dev NOTES**\n<details>\n\nthe above metrics are absolute nos and not %ges"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d062350d-4382-4d09-a7c7-25fc7cc0c388"}}},{"cell_type":"markdown","source":["In this example we are choosing LM model for pipelining. General criteria for choosing production models is:\n\n- Parametric models (aka whitebox models) such as Linear Regression are easier to explain to non-technical audience.\n- Generally these are accepted fast and adoption is quicker.\n- If the downstream calls for optimization using these models parametric models are easier to implement.\n- When accuracy is primary goal without explainability, the above two takes a backseat"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ac66b719-64f3-4ece-8140-4a241deec146"}}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.9","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"03_model_experimenting","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2486657885092227}},"nbformat":4,"nbformat_minor":0}
